"""
Deep Research Agent - Pesquisa em m√∫ltiplas camadas usando Exa e Cerebras
Baseado no notebook Deep_Research_agents_Nvidia.ipynb
"""

import os
from typing import List, Dict, Optional
from crewai import Agent, LLM

# Importar as bibliotecas necess√°rias
try:
    from exa_py import Exa
    from cerebras.cloud.sdk import Cerebras
except ImportError as e:
    print(f"‚ö†Ô∏è Erro ao importar bibliotecas: {e}")
    print("Certifique-se de ter instalado: pip install exa-py cerebras-cloud-sdk")
    raise

class DeepResearchAgent:
    """Agente especializado em pesquisa profunda usando Exa e Cerebras"""
    
    def __init__(self):
        """Inicializa o agente com as APIs necess√°rias"""
        # Carregar chaves de API
        self.exa_api_key = os.environ.get("EXA_API_KEY")
        self.cerebras_api_key = os.environ.get("CEREBRAS_API_KEY")
        
        if not self.exa_api_key:
            raise ValueError("EXA_API_KEY n√£o encontrada. Configure no arquivo keys.env")
        if not self.cerebras_api_key:
            raise ValueError("CEREBRAS_API_KEY n√£o encontrada. Configure no arquivo keys.env")
        
        # Inicializar clientes das APIs
        try:
            self.exa_client = Exa(api_key=self.exa_api_key)
            self.cerebras_client = Cerebras(api_key=self.cerebras_api_key)
            print("‚úÖ APIs Exa e Cerebras inicializadas com sucesso")
        except Exception as e:
            print(f"‚ùå Erro ao inicializar APIs: {e}")
            raise
    
    def search_web_exa(self, query: str, num_results: int = 5) -> List[Dict]:
        """
        Realiza busca na web usando Exa API
        Baseado na fun√ß√£o search_web do notebook
        """
        try:
            print(f"üîç Buscando: '{query}' (at√© {num_results} resultados)")
            
            result = self.exa_client.search_and_contents(
                query,
                type="auto",
                num_results=num_results,
                text={"max_characters": 1000}
            )
            
            # Processar resultados
            sources = []
            for res in result.results:
                if hasattr(res, 'text') and res.text:
                    sources.append({
                        "title": getattr(res, 'title', 'Sem t√≠tulo'),
                        "content": res.text,
                        "url": getattr(res, 'url', ''),
                        "published_date": getattr(res, 'published_date', '')
                    })
            
            print(f"‚úì Encontrados {len(sources)} resultados relevantes")
            return sources
            
        except Exception as e:
            print(f"‚ùå Erro na busca Exa: {e}")
            return []
    
    def analyze_with_cerebras(self, prompt: str, max_tokens: int = 600, temperature: float = 0.2) -> str:
        """
        Analisa conte√∫do usando Cerebras AI
        Baseado na fun√ß√£o ask_ai do notebook
        """
        try:
            print(f"üß† Analisando com Cerebras (max_tokens={max_tokens})")
            
            chat_completion = self.cerebras_client.chat.completions.create(
                messages=[
                    {
                        "role": "user",
                        "content": prompt,
                    }
                ],
                model="llama-4-scout-17b-16e-instruct",
                max_tokens=max_tokens,
                temperature=temperature
            )
            
            response = chat_completion.choices[0].message.content
            print("‚úì An√°lise conclu√≠da")
            return response
            
        except Exception as e:
            print(f"‚ùå Erro na an√°lise Cerebras: {e}")
            return ""
    
    def generate_followup_question(self, initial_sources: List[Dict], original_query: str) -> str:
        """
        Gera uma pergunta de aprofundamento baseada nas fontes iniciais
        """
        # Criar contexto das fontes iniciais
        context = f"Pesquisa original: {original_query}\n\nFontes encontradas:\n"
        for i, source in enumerate(initial_sources[:4], 1):
            context += f"{i}. {source['title']}: {source['content'][:300]}...\n\n"
        
        # Prompt para gerar pergunta de follow-up
        prompt = f"""{context}

Com base nestas fontes sobre "{original_query}", qual √© a pergunta de acompanhamento mais importante 
que aprofundaria nosso entendimento sobre as startups investidas e seus detalhes espec√≠ficos?

Responda apenas com uma consulta de pesquisa espec√≠fica e focada (sem explica√ß√£o):"""
        
        followup = self.analyze_with_cerebras(prompt, max_tokens=100, temperature=0.3)
        return followup.strip().strip('"')
    
    def synthesize_results(self, all_sources: List[Dict], original_query: str, followup_query: str) -> str:
        """
        Sintetiza todos os resultados em um formato estruturado JSON
        """
        # Criar contexto completo
        context = f"Pesquisa original: {original_query}\n"
        context += f"Pesquisa de aprofundamento: {followup_query}\n\n"
        context += "Todas as fontes coletadas:\n"
        
        for i, source in enumerate(all_sources[:8], 1):
            prefix = "[Aprofundamento] " if i > 4 else ""
            context += f"{i}. {prefix}{source['title']}: {source['content'][:400]}...\n\n"
        
        # Prompt final para gerar lista estruturada
        prompt = f"""{context}

Com base em TODAS as fontes acima, liste as startups que foram investidas pelas VCs mencionadas.

IMPORTANTE: Sua resposta deve ser APENAS uma lista JSON v√°lida, sem nenhum texto adicional antes ou depois.
Cada startup deve ser um objeto com TODAS as seguintes chaves (use "N√£o informado" se n√£o encontrar a informa√ß√£o):

[
  {{
    "nome": "Nome da Startup",
    "site": "https://...",
    "setor": "Categoria/Ind√∫stria",
    "ano_fundacao": "Ano",
    "valor_investimento": "Valor em USD",
    "rodada": "S√©rie/Rodada",
    "data_investimento": "Data",
    "vc_investidor": "Nome da VC",
    "descricao_breve": "Breve descri√ß√£o do que a empresa faz",
    "linkedin_fundador": "Link do LinkedIn ou 'N√£o informado'"
  }}
]

Retorne APENAS o JSON, sem explica√ß√µes ou texto adicional:"""
        
        response = self.analyze_with_cerebras(prompt, max_tokens=800, temperature=0.1)
        return response


# Criar inst√¢ncia do agente CrewAI
def create_deep_research_crewai_agent():
    """Cria um agente CrewAI que usa o DeepResearchAgent internamente"""
    
    # Usar o LLM padr√£o do CrewAI para o agente (pode ser OpenAI ou Perplexity)
    agent = Agent(
        role="Especialista em Pesquisa Profunda de VCs",
        goal="Realizar pesquisa em m√∫ltiplas camadas para encontrar informa√ß√µes detalhadas sobre startups investidas",
        backstory=(
            "Voc√™ √© um especialista em pesquisa profunda que utiliza t√©cnicas avan√ßadas de busca em m√∫ltiplas "
            "camadas. Primeiro realiza uma pesquisa ampla, depois gera perguntas de aprofundamento inteligentes "
            "e finalmente sintetiza todas as informa√ß√µes em relat√≥rios estruturados e completos."
        ),
        verbose=True,
        allow_delegation=False
    )
    
    # Anexar o DeepResearchAgent como ferramenta customizada
    agent._deep_research = DeepResearchAgent()
    
    return agent